{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This task involves creating a Reddit Flair Detector. I have first \n",
    "preprocessed the data extracted from r/india.\n",
    "After preprocessing, I tested the data with 3 classifier, Naive Bayees,\n",
    "Support Vector Machine and Logistic Regression. The accuracy of Logistic\n",
    "Regression was the highest, so I made my model using that. I uploaded my dataset \n",
    "on mongodb using atlas and studio 3T. I used that database test the models. \n",
    "I saved my final model, logistic regression in .sav file, to be able to use it\n",
    "while predicting.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Removing the stopwords'''\n",
    "def remove_stopwords(text):\n",
    "\tfor w in text:\n",
    "\t\tif w == \"\\n\":\n",
    "\t\t\tw= \" \"\n",
    "\twords = [w for w in text if w not in stopwords.words(\"english\")]\n",
    "\treturn words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Stemming using Porter Stemmer. It involves converting all words to their root word'''\n",
    "ps= PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "\tlis = []\n",
    "\tfor t in text:\n",
    "\t\tt = str(t)\n",
    "\t\taux_l = \"\"\n",
    "\t\twords = []\n",
    "\t\twords = word_tokenize(t)\n",
    "\t\tfor w in words:\n",
    "\t\t\trootword = ps.stem(w)\n",
    "\t\t\tif(rootword.isalnum()):\n",
    "\t\t\t\taux_l = aux_l+ rootword+ \" \"\n",
    "\t\tlis.append(str(aux_l))\n",
    "\treturn lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Reading the database to preprocess, convert items to use and preprocess in a list'''\n",
    "df = pd.read_csv('testset.csv')\n",
    "df.fillna(\"\")\n",
    "title= df[\"title\"].tolist()\n",
    "body= df[\"body\"].tolist()\n",
    "comment = df[\"comments\"].tolist()\n",
    "#print(\"-----------------\")\n",
    "#print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Removing stopwords from title, body and comments'''\n",
    "t_remove = remove_stopwords(title)\n",
    "b_remove = remove_stopwords(body)\n",
    "c_remove = remove_stopwords(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Converting to dataframe and storing in a csv file'''\n",
    "df[\"title\"] = t_remove\n",
    "df[\"body\"] = b_remove\n",
    "df[\"comments\"] = c_remove\n",
    "df.to_csv(\"test_stopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for c in comment:\\n\\tval = stemming(c)\\n\\tprint(val)\\n\\tc_remove_stem.append(val)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Reading csv file with remove stopwords and applying stemming on them.'''\n",
    "df = pd.read_csv('test_stopwords.csv')\n",
    "df.fillna(\"\")\n",
    "title= df[\"title\"].tolist()\n",
    "body= df[\"body\"].tolist()\n",
    "comment = df[\"comments\"].tolist()\n",
    "t_remove_stem= stemming(title)\n",
    "b_remove_stem = stemming(body)\n",
    "c_remove_stem =  stemming(comment)\n",
    "#c_remove_stem = stemming(c_remove)\n",
    "#print(t_remove_stem)\n",
    "#print(\"---------------------------------\")\n",
    "#print(b_remove_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Converting stemmed data to data frame'''\n",
    "t1 = pd.DataFrame(t_remove_stem)\n",
    "b1 = pd.DataFrame(b_remove_stem)\n",
    "c1 = pd.DataFrame(c_remove_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving the data into a csv file'''\n",
    "df[\"title\"] = t1\n",
    "df[\"body\"] = b1\n",
    "df[\"comments\"] = c1\n",
    "df.to_csv(\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''declaring list of target flairs for model testing'''\n",
    "flairs = [\"Scheduled\", \"Politics\", \"Photography\",\"Policy/Economy\",\n",
    "         \"Sports\",\"Non-Political\",\"Science/Technology\",\"Food\",\n",
    "            \"Business/Finance\",\"Coronavirus\",\"Megathread\",\"CAA-NRC\",\"[R]eddiquette\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.head())\n",
    "#y = df[\"flair\"]\n",
    "#x = df.drop(\"flair\", axis = 1)\n",
    "#print(x)\n",
    "#print(y)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n",
    "#print(x_train)\n",
    "#print(x_train.shape, x_test.shape)\n",
    "#print(x_test)\n",
    "#train = x_train.to_csv(\"train.csv\")\n",
    "#test = x_test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing the data along 3 classifiers: Naive Bayees,\n",
    "Support Vector Machine and Logistic Regression. Used sklearn library for the same'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Naive Bayees Classfier'''\n",
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "\tfrom sklearn.naive_bayes import MultinomialNB\n",
    "\tnb = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "\tnb.fit(X_train, y_train)\n",
    "\ty_pred = nb.predict(X_test)\n",
    "\tnew_l = []\n",
    "\t\"\"\"for i in flairs:\n",
    "\t\t\t\t\tif(i in y_test):\n",
    "\t\t\t\t\t\tnew_l.append(i)\"\"\"\n",
    "\tprint(\"Results of Naive Bayes Classifier\")\n",
    "\tprint('accuracy ' + str(accuracy_score(y_pred, y_test)))\n",
    "\tprint(\"Classification Report is: \")\n",
    "\tprint(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SVM Classifier'''\n",
    "def svm_classifier(X_train,X_test,y_train,y_test):\n",
    "\tfrom sklearn.linear_model import SGDClassifier\n",
    "\tsvm = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier()),])\n",
    "\tsvm.fit(X_train, y_train)\n",
    "\ty_pred = svm.predict(X_test)\n",
    "\tnew_l = []\n",
    "\t\"\"\"for i in flairs:\n",
    "\t\t\t\t\tif(i in y_test):\n",
    "\t\t\t\t\t\tnew_l.append(i)\"\"\"\n",
    "\n",
    "\tprint(\"Results of Support Vector Machine Classifier\")\n",
    "\tprint('accuracy ' + str(accuracy_score(y_pred, y_test)))\n",
    "\tprint(\"Classification Report is: \")\n",
    "\tprint(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Logistic Regression Classifier'''\n",
    "def logreg_classifier(X_train,X_test,y_train,y_test):\n",
    "\tfrom sklearn.linear_model import LogisticRegression\n",
    "\tlgr = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LogisticRegression()),])\n",
    "\tlgr.fit(X_train, y_train)\n",
    "\tnew_l = []\n",
    "\tfilename = 'finalized_model.sav'\n",
    "\tpickle.dump(lgr, open(filename, 'wb'))\n",
    "\ty_pred = lgr.predict(X_test)\n",
    "\t\n",
    "\tprint(\"Results of Logistic Regression\")\n",
    "\tprint('accuracy ' + str(accuracy_score(y_pred, y_test)))\n",
    "\tprint(\"Classification Report is: \")\n",
    "\tprint(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dividing the data into training and test dataset'''\n",
    "def train_test(X,y):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\t#nb_classifier(X_train, X_test, y_train, y_test)\n",
    "\t#svm_classifier(X_train, X_test, y_train, y_test)\n",
    "\tlogreg_classifier(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Reading the data from MongoDB. Used pymongo to do the same.'''\n",
    "#df = pd.read_csv('preprocessed.csv')\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['Midaas']\n",
    "preprocess = db.preprocessed\n",
    "df = pd.DataFrame(list(preprocess.find()))\n",
    "df[\"flair\"] = df[\"flair\"].values.astype('U')\n",
    "df[\"comments\"] = df[\"comments\"].values.astype('U')\n",
    "df[\"title\"] = df[\"title\"].values.astype('U')\n",
    "df[\"body\"] = df[\"body\"].values.astype('U')\n",
    "fl = df[\"flair\"].tolist()\n",
    "com = df[\"comments\"].tolist()\n",
    "tit = df[\"title\"].tolist()\n",
    "bod = df[\"body\"].tolist()\n",
    "combined = (df[\"comments\"]+ df[\"title\"]+df[\"body\"]).tolist()\n",
    "#df = df.assign(combine = combined)\n",
    "#com = df.combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Title as Feature\n",
      "Results of Logistic Regression\n",
      "accuracy 0.5308219178082192\n",
      "Classification Report is: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.52      0.41      0.45        74\n",
      "          Politics       0.64      0.76      0.69        70\n",
      "       Photography       0.40      0.59      0.48        64\n",
      "    Policy/Economy       0.61      0.54      0.57        79\n",
      "            Sports       0.00      0.00      0.00         2\n",
      "     Non-Political       0.26      0.28      0.27        68\n",
      "Science/Technology       0.77      0.63      0.70        76\n",
      "              Food       0.42      0.48      0.45        71\n",
      "  Business/Finance       0.36      0.40      0.38        73\n",
      "       Coronavirus       0.88      0.96      0.92        85\n",
      "        Megathread       0.31      0.45      0.37        66\n",
      "           CAA-NRC       0.86      0.64      0.73        69\n",
      "     [R]eddiquette       0.48      0.19      0.27        79\n",
      "\n",
      "          accuracy                           0.53       876\n",
      "         macro avg       0.50      0.49      0.48       876\n",
      "      weighted avg       0.55      0.53      0.53       876\n",
      "\n",
      "Flair Detection using Body as Feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "accuracy 0.2237442922374429\n",
      "Classification Report is: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.67      0.02      0.04        87\n",
      "          Politics       0.00      0.00      0.00        80\n",
      "       Photography       0.00      0.00      0.00        77\n",
      "    Policy/Economy       0.78      0.23      0.36        78\n",
      "            Sports       0.00      0.00      0.00         1\n",
      "     Non-Political       0.00      0.00      0.00        69\n",
      "Science/Technology       0.10      0.97      0.18        61\n",
      "              Food       0.31      0.14      0.19        71\n",
      "  Business/Finance       0.00      0.00      0.00        83\n",
      "       Coronavirus       0.95      0.95      0.95        81\n",
      "        Megathread       0.32      0.17      0.22        71\n",
      "           CAA-NRC       0.00      0.00      0.00        60\n",
      "     [R]eddiquette       0.17      0.32      0.22        57\n",
      "\n",
      "          accuracy                           0.22       876\n",
      "         macro avg       0.25      0.22      0.17       876\n",
      "      weighted avg       0.29      0.22      0.18       876\n",
      "\n",
      "Flair Detection using Comments as Feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "accuracy 0.5582191780821918\n",
      "Classification Report is: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.56      0.40      0.47        78\n",
      "          Politics       0.66      0.66      0.66        76\n",
      "       Photography       0.32      0.48      0.39        69\n",
      "    Policy/Economy       0.70      0.81      0.75        68\n",
      "            Sports       0.00      0.00      0.00         1\n",
      "     Non-Political       0.33      0.21      0.26        75\n",
      "Science/Technology       0.59      0.83      0.69        69\n",
      "              Food       0.36      0.47      0.41        62\n",
      "  Business/Finance       0.55      0.69      0.61        93\n",
      "       Coronavirus       0.96      0.92      0.94        79\n",
      "        Megathread       0.46      0.30      0.36        71\n",
      "           CAA-NRC       0.84      0.47      0.60        68\n",
      "     [R]eddiquette       0.45      0.42      0.43        67\n",
      "\n",
      "          accuracy                           0.56       876\n",
      "         macro avg       0.52      0.51      0.50       876\n",
      "      weighted avg       0.57      0.56      0.55       876\n",
      "\n",
      "Flair Detection using Combined Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "accuracy 0.6438356164383562\n",
      "Classification Report is: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Scheduled       0.59      0.43      0.50        82\n",
      "          Politics       0.70      0.70      0.70        60\n",
      "       Photography       0.54      0.70      0.61        73\n",
      "    Policy/Economy       0.77      0.81      0.79        63\n",
      "            Sports       0.00      0.00      0.00         2\n",
      "     Non-Political       0.45      0.33      0.38        64\n",
      "Science/Technology       0.86      0.84      0.85        85\n",
      "              Food       0.46      0.58      0.52        72\n",
      "  Business/Finance       0.53      0.65      0.58        77\n",
      "       Coronavirus       0.92      0.92      0.92        75\n",
      "        Megathread       0.52      0.58      0.55        74\n",
      "           CAA-NRC       0.93      0.76      0.83        83\n",
      "     [R]eddiquette       0.48      0.39      0.43        66\n",
      "\n",
      "          accuracy                           0.64       876\n",
      "         macro avg       0.60      0.59      0.59       876\n",
      "      weighted avg       0.65      0.64      0.64       876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''Printing results of the final model for title, body,comments and combined'''\n",
    "print(\"Flair Detection using Title as Feature\")\n",
    "train_test(tit,fl)\n",
    "print(\"Flair Detection using Body as Feature\")\n",
    "train_test(bod,fl)\n",
    "print(\"Flair Detection using Comments as Feature\")\n",
    "train_test(com,fl)\n",
    "print(\"Flair Detection using Combined Features\")\n",
    "train_test(combined,fl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
